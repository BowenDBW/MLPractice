{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 ('base')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T11:51:01.640092Z",
     "start_time": "2023-07-14T11:51:01.598432100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score # other metrics are allowed here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T11:51:01.748205900Z",
     "start_time": "2023-07-14T11:51:01.614029900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the csv file\n",
    "data = pd.read_csv(\"cleveland.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T11:51:01.862665300Z",
     "start_time": "2023-07-14T11:51:01.627487400Z"
    }
   },
   "outputs": [],
   "source": [
    "# pairplot to check the correlation\n",
    "#fig = sns.pairplot(data)\n",
    "#fig.savefig(\"./pair_plot.png\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T11:51:01.862665300Z",
     "start_time": "2023-07-14T11:51:01.646938700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0   age  sex   cp  trestbps   chol  fbs  restecg  thalach  \\\n0             0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0   \n1             1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0   \n2             2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0   \n3             3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0   \n4             4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0   \n..          ...   ...  ...  ...       ...    ...  ...      ...      ...   \n298         298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0   \n299         299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0   \n300         300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0   \n301         301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0   \n302         302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0   \n\n     exang  oldpeak  slope   ca  thal  target  \n0      0.0      2.3    3.0  0.0   6.0      -1  \n1      1.0      1.5    2.0  3.0   3.0       1  \n2      1.0      2.6    2.0  2.0   7.0       1  \n3      0.0      3.5    3.0  0.0   3.0      -1  \n4      0.0      1.4    1.0  0.0   3.0      -1  \n..     ...      ...    ...  ...   ...     ...  \n298    0.0      1.2    2.0  0.0   7.0       1  \n299    0.0      3.4    2.0  2.0   7.0       1  \n300    1.0      1.2    2.0  1.0   7.0       1  \n301    0.0      0.0    2.0  1.0   3.0       1  \n302    0.0      0.0    1.0  0.0   3.0      -1  \n\n[303 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>63.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>2.3</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>108.0</td>\n      <td>1.0</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>129.0</td>\n      <td>1.0</td>\n      <td>2.6</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>37.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>187.0</td>\n      <td>0.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n      <td>204.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>172.0</td>\n      <td>0.0</td>\n      <td>1.4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>298</td>\n      <td>45.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>110.0</td>\n      <td>264.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>132.0</td>\n      <td>0.0</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>299</td>\n      <td>68.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>144.0</td>\n      <td>193.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>141.0</td>\n      <td>0.0</td>\n      <td>3.4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>300</td>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>130.0</td>\n      <td>131.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>115.0</td>\n      <td>1.0</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>301</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n      <td>236.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>174.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>302</td>\n      <td>38.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>138.0</td>\n      <td>175.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>173.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the index file\n",
    "with open('experiments.pkl', 'rb') as f:\n",
    "    inds = pkl.load(f)\n",
    "\n",
    "# shuffle the dataframe according to the index, and\n",
    "# split the dataframe into 0.8/0.2 train-test sets.\n",
    "train_inds, test_inds = inds[:int(0.8*len(inds))], inds[int(0.8*len(inds)):]\n",
    "\n",
    "# convert the target value to {-1, 1}\n",
    "for i in range(0, data.shape[0]):\n",
    "    if data['target'].loc[data.index[i]] > 0:\n",
    "        data.loc[i, 'target'] = 1\n",
    "    else:\n",
    "        data.loc[i, 'target'] = -1\n",
    "# target value: 0-healthy, 1,2,3,4-high risk of heart disease\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T11:51:01.865013200Z",
     "start_time": "2023-07-14T11:51:01.707221900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.73545228, -1.38407465, -0.13972393, ..., -1.0057096 ,\n        -0.69292967, -0.87575498],\n       [ 0.60525922, -1.38407465, -0.13972393, ..., -1.0057096 ,\n         0.38199969, -0.87575498],\n       [ 0.9404371 ,  0.72250438,  0.88491822, ...,  0.6387615 ,\n         0.38199969,  1.20712172],\n       ...,\n       [ 1.61079285, -1.38407465, -2.18900823, ..., -1.0057096 ,\n         1.45692905, -0.87575498],\n       [-1.07063016,  0.72250438,  0.88491822, ..., -1.0057096 ,\n        -0.69292967, -0.87575498],\n       [-0.28854845,  0.72250438,  0.88491822, ..., -1.0057096 ,\n         1.45692905,  1.20712172]])"
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = data.loc[train_inds]\n",
    "test_set = data.loc[test_inds]\n",
    "\n",
    "# scale the data (train & test) using the sklearn StandardScaler.\n",
    "scaler = StandardScaler()\n",
    "train_param = scaler.fit_transform(train_set.iloc[:, 1: 14])\n",
    "test_param = scaler.fit_transform(test_set.iloc[:, 1: 14])\n",
    "train_target = train_set.iloc[:, 14: 15]\n",
    "test_target = test_set.iloc[:, 14: 15]\n",
    "\n",
    "train_param"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Simple Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T12:17:36.919444Z",
     "start_time": "2023-07-14T12:17:36.854814100Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# logistic regression\n",
    "# upload your logistic_regression.py\n",
    "def sigmoid(x):\n",
    "    # the sigmoid function\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "class LogisticReg(object):\n",
    "    def __init__(self, indim=1):\n",
    "        # initialize the parameters with all zeros\n",
    "        # w: shape of [d+1, 1]\n",
    "        self.w = np.zeros(shape=(indim + 1, 1))\n",
    "\n",
    "    def set_param(self, weights, bias):\n",
    "        # helper function to set the parameters\n",
    "        # NOTE: you need to implement this to pass the autograde.\n",
    "        # weights: vector of shape [d, ]\n",
    "        # bias: scaler\n",
    "        self.w[:-1, :] = weights.reshape(weights.shape[0], 1)\n",
    "        self.w[-1, 0] = bias\n",
    "\n",
    "    def get_param(self):\n",
    "        # helper function to return the parameters\n",
    "        # NOTE: you need to implement this to pass the autograde.\n",
    "        # returns:\n",
    "        # weights: vector of shape [d, ]\n",
    "        # bias: scaler\n",
    "        weights = self.w[:-1, :].reshape(self.w[:-1, :].shape[0],)\n",
    "        bias = self.w[-1, 0]\n",
    "        return weights, bias\n",
    "\n",
    "    def compute_loss(self, X, t):\n",
    "        # compute the loss\n",
    "        # X: feature matrix of shape [N, d]\n",
    "        # t: input label of shape [N, ]\n",
    "        # NOTE: return the average of the log-likelihood, NOT the sum.\n",
    "\n",
    "        # extend the input matrix\n",
    "\n",
    "        # compute the loss and return the loss\n",
    "        # X变换\n",
    "        # t变换\n",
    "        # 套公式\n",
    "        X = np.hstack([X, np.ones(shape=[X.shape[0], 1])])\n",
    "        t = np.expand_dims(t, 1)\n",
    "        z = sigmoid((X @ self.w) * t)\n",
    "        return -np.log(z).mean()\n",
    "\n",
    "    def compute_grad(self, X, t):\n",
    "        # X: feature matrix of shape [N, d]\n",
    "        # grad: shape of [d, 1]\n",
    "        # NOTE: return the average gradient, NOT the sum.\n",
    "        X = np.hstack([X, np.ones(shape=[X.shape[0], 1])])\n",
    "        t = np.expand_dims(t, 1)\n",
    "        z = sigmoid(X @ self.w * t)\n",
    "        return (- (1 - z) * (t * X)).mean(axis=1, keepdims=True)[0][0].reshape(X.shape[1],1)\n",
    "\n",
    "\n",
    "    def update(self, grad, lr=0.001):\n",
    "        # update the weights\n",
    "        # by the gradient descent rule\n",
    "\n",
    "        # 梯度下降法\n",
    "        self.w = self.w - grad.T * lr\n",
    "\n",
    "    def fit(self, X, t, lr=0.001, max_iters=1000, eps=1e-7):\n",
    "        # implement the .fit() using the gradient descent method.\n",
    "        # args:\n",
    "        #   X: input feature matrix of shape [N, d]\n",
    "        #   t: input label of shape [N, ]\n",
    "        #   lr: learning rate\n",
    "        #   max_iters: maximum number of iterations\n",
    "        #   eps: tolerance of the loss difference\n",
    "        # TO NOTE:\n",
    "        #   extend the input features before fitting to it.\n",
    "        #   return the weight matrix of shape [indim+1, 1]\n",
    "\n",
    "        loss = 1e10\n",
    "        j = 1\n",
    "        for epoch in range(max_iters):\n",
    "            # compute the loss\n",
    "            new_loss = self.compute_loss(X, t)\n",
    "\n",
    "            # compute the gradient\n",
    "            grad = self.compute_grad(X, t)\n",
    "\n",
    "            # update the weight\n",
    "            self.update(grad, lr=lr)\n",
    "            log = \"loss for epoch \" + str(j) + \" is:\" + str(new_loss)\n",
    "            print(log)\n",
    "            j += 1\n",
    "            # decide whether to break the loop\n",
    "            if np.abs(new_loss - loss) < eps:\n",
    "                return self.w\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "        # implement the .predict_prob() using the parameters learned by .fit()\n",
    "        # X: input feature matrix of shape [N, d]\n",
    "        #   NOTE: make sure you extend the feature matrix first,\n",
    "        #   the same way as what you did in .fit() method.\n",
    "        # returns the prediction (likelihood) of shape [N, ]\n",
    "        X = np.hstack([X, np.ones(shape=[X.shape[0], 1])])\n",
    "        return sigmoid(np.dot(X, self.w))\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        # implement the .predict() using the .predict_prob() method\n",
    "        # X: input feature matrix of shape [N, d]\n",
    "        # returns the prediction of shape [N, ], where each element is -1 or 1.\n",
    "        # if the probability p>threshold, we determine t=1, otherwise t=-1\n",
    "        res = []\n",
    "        X = self.predict_prob(X)\n",
    "        for x in np.nditer(X):\n",
    "            if x > threshold:\n",
    "                res.append(1)\n",
    "            else:\n",
    "                res.append(-1)\n",
    "        return np.array(res).T\n",
    "# from logisitic_regression import LogisticReg\n",
    "# create the model\n",
    "model = DecisionTreeClassifier(criterion='gini',max_depth=4,random_state=1)\n",
    "# train the model\n",
    "model.fit(train_param, train_target)\n",
    "# plot the training & test losses.\n",
    "predict_train = model.predict(train_param)\n",
    "predict_test = model.predict(test_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T12:17:38.291576200Z",
     "start_time": "2023-07-14T12:17:38.253535600Z"
    }
   },
   "outputs": [],
   "source": [
    "# report the training and testing accuracies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T12:17:42.412700900Z",
     "start_time": "2023-07-14T12:17:42.395496100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for train set is\n",
      "[[ 87   3]\n",
      " [ 25 127]]\n",
      "f1 for train set is\n",
      "[[21  9]\n",
      " [ 6 25]]\n",
      "confusion matrix for test set is\n",
      "0.5723684210526315\n",
      "f1 for test set is\n",
      "0.5526315789473684\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "predict_train = np.array(predict_train)\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "def get_mat_and_f1(predict, target):\n",
    "    predict = predict.reshape(predict.shape[0],1)\n",
    "    target = np.array(target)\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for i in range(0, target.shape[0]):\n",
    "        if predict[i] == 1 and target[i] == 1:\n",
    "            tp += 1\n",
    "        elif predict[i] == 1 and target[i] == -1:\n",
    "            fp += 1\n",
    "        elif predict[i] == -1 and target[i] == 1:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "# F1 Score\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 / (1 / precision + 1 / recall)\n",
    "    return np.array([[tp, fp], [tn, fn]]), f1\n",
    "\n",
    "# Other metrics\n",
    "train_mat, train_f1 = get_mat_and_f1(predict_train, train_target)\n",
    "test_mat, test_f1 = get_mat_and_f1(predict_test, test_target)\n",
    "print(\"confusion matrix for train set is\")\n",
    "print(train_mat)\n",
    "print(\"f1 for train set is\")\n",
    "print(test_mat)\n",
    "print(\"confusion matrix for test set is\")\n",
    "print(train_f1)\n",
    "print(\"f1 for test set is\")\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T11:51:36.573329700Z",
     "start_time": "2023-07-14T11:51:36.079415Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\BowenDeng\\.conda\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 19  62 106 149 193] [[1.         1.         1.         1.         1.        ]\n",
      " [0.90322581 0.88709677 0.87096774 0.87096774 0.87096774]\n",
      " [0.90566038 0.88679245 0.88679245 0.87735849 0.87735849]\n",
      " [0.89261745 0.88590604 0.87248322 0.88590604 0.87919463]\n",
      " [0.89637306 0.88601036 0.89119171 0.88082902 0.88601036]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (5,)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[330], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m train_loss, test_loss, valid_scores \u001B[38;5;241m=\u001B[39m learning_curve(\n\u001B[0;32m      4\u001B[0m SVC(kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m'\u001B[39m), train_param, train_target)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(train_loss, test_loss)\n\u001B[1;32m----> 6\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam_range\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mo-\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTraining\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(param_range, test_loss, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mo-\u001B[39m\u001B[38;5;124m'\u001B[39m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mg\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      9\u001B[0m label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCross-validation\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     10\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgamma\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\data\\lib\\site-packages\\matplotlib\\pyplot.py:2812\u001B[0m, in \u001B[0;36mplot\u001B[1;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2810\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mplot)\n\u001B[0;32m   2811\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot\u001B[39m(\u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scaley\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 2812\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m gca()\u001B[38;5;241m.\u001B[39mplot(\n\u001B[0;32m   2813\u001B[0m         \u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39mscalex, scaley\u001B[38;5;241m=\u001B[39mscaley,\n\u001B[0;32m   2814\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m: data} \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\data\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001B[0m, in \u001B[0;36mAxes.plot\u001B[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1445\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1446\u001B[0m \u001B[38;5;124;03mPlot y versus x as lines and/or markers.\u001B[39;00m\n\u001B[0;32m   1447\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1685\u001B[0m \u001B[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001B[39;00m\n\u001B[0;32m   1686\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1687\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m cbook\u001B[38;5;241m.\u001B[39mnormalize_kwargs(kwargs, mlines\u001B[38;5;241m.\u001B[39mLine2D)\n\u001B[1;32m-> 1688\u001B[0m lines \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_lines(\u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39mdata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)]\n\u001B[0;32m   1689\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines:\n\u001B[0;32m   1690\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_line(line)\n",
      "File \u001B[1;32m~\\.conda\\envs\\data\\lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001B[0m, in \u001B[0;36m_process_plot_var_args.__call__\u001B[1;34m(self, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m     this \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    310\u001B[0m     args \u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_plot_args\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mambiguous_fmt_datakey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mambiguous_fmt_datakey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\data\\lib\\site-packages\\matplotlib\\axes\\_base.py:504\u001B[0m, in \u001B[0;36m_process_plot_var_args._plot_args\u001B[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001B[0m\n\u001B[0;32m    501\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes\u001B[38;5;241m.\u001B[39myaxis\u001B[38;5;241m.\u001B[39mupdate_units(y)\n\u001B[0;32m    503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m--> 504\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y must have same first dimension, but \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    505\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhave shapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m y\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    507\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y can be no greater than 2D, but have \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    508\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: x and y must have same first dimension, but have shapes (1,) and (5,)"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Further analysis and improvement."
   ]
  }
 ]
}
